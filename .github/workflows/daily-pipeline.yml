name: Daily Data Pipeline

on:
  schedule:
    - cron: "0 1 * * *"   # 每天 UTC 01:00（北京 09:00）
  workflow_dispatch:

# 防止并发跑导致 push 冲突（你这个 workflow 会 push 回 main，强烈建议开启）
concurrency:
  group: daily-pipeline
  cancel-in-progress: true

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  pipeline:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: pipeline/requirements.txt

      - name: Install dependencies
        run: pip install -r pipeline/requirements.txt

      - name: Run pipeline
        env:
          DASHSCOPE_API_KEY: ${{ secrets.DASHSCOPE_API_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          OUTPUT_DIR: output
          DATA_DIR: data
        run: python -m pipeline.main

      - name: Copy output to data directories
        run: |
          DATE=$(date -u +%Y-%m-%d)
          if [ -f output/daily.json ]; then
            mkdir -p data frontend/public/data
            cp output/daily.json "data/${DATE}.json"
            cp output/daily.json "frontend/public/data/${DATE}.json"
            cp output/daily.json frontend/public/data/latest.json
          else
            echo "output/daily.json not found, skipping copy"
          fi

      - name: Commit and push data
        run: |
          set -e
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          DATE=$(date -u +%Y-%m-%d)

          git add data/ frontend/public/data/
          git commit -m "data: ${DATE} daily update" || echo "No changes to commit"

          # 拉取远端最新，遇到数据文件冲突时用本地版本覆盖
          git pull --rebase -X theirs origin main || true

          # 并发情况下仍可能失败，重试几次
          for i in 1 2 3 4 5; do
            git push && break
            echo "Push failed, retrying in 5s... ($i/5)"
            sleep 5
            git pull --rebase -X theirs origin main || true
          done

      - name: Cleanup old data (> 30 days)
        run: |
          set -e
          find data/ -name "*.json" -mtime +30 ! -name "star_history.json" -delete 2>/dev/null || true
          find frontend/public/data/ -name "*.json" -mtime +30 ! -name "latest.json" -delete 2>/dev/null || true

          git add -A
          if git diff --cached --quiet; then
            echo "No cleanup changes"
            exit 0
          fi

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git commit -m "chore: cleanup old data"

          git pull --rebase -X theirs origin main || true
          for i in 1 2 3 4 5; do
            git push && break
            echo "Push failed, retrying in 5s... ($i/5)"
            sleep 5
            git pull --rebase -X theirs origin main || true
          done

      # ---- 构建前端并部署到 GitHub Pages ----
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "20"
          cache: "npm"
          cache-dependency-path: frontend/package-lock.json

      - name: Build frontend
        run: |
          cd frontend
          npm ci
          npm run build

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./frontend/dist

      # ---- 闲鱼文案推送（4 条 + 汇报） ----
      - name: Run share_emd
        env:
          DASHSCOPE_API_KEY: ${{ secrets.DASHSCOPE_API_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          SHARE_XLSX_PATH: data/share_modules.xlsx
        run: python share_emd.py 4
